# Awesome Data Science Dictionary
{Work in Process... Stay Tuned}



* ERD   - Entity Relationship Diagrams
* ETL   - Extract, Transform and Load
* ELT   - Extract, Load and Transform
* KPI   - Key Performance Indicator
* LCDP  - A low-code development platform (LCDP) is software that provides an environment programmers use to create application software through graphical user interfaces and configuration instead of traditional computer programming
* OLAP  - Online Analytical Processing
* OLTP  - Online Transaction Processing
* SaaS  - Software as a Service
* PaaS  - Platform as a Service
* IaaS  - Infrastructure as a Service
  * [SaaS vs PaaS vs IaaS: What’s The Difference and How To Choose](https://www.bmc.com/blogs/saas-vs-paas-vs-iaas-whats-the-difference-and-how-to-choose/)
* DFaaS - Data Fabrics as a Service 
  * [What Is a Data Fabric?](https://www.netapp.com/us/info/what-is-data-fabric.aspx)
* DW    - Data Warehouse
* DSS   - Decision Support System
* EDW   - Enterprise Data Warehouse
* VLDB  - Very Large Database
* BISM  - Business Intelligence Semantic Model
* CRISP-DM - Cross-Industry Standard Process for Data Mining
* RDBMS - Relational Database Management System
* PSA   - Persistent Staging Area 
  * [Using a Persistent Staging Area: What, Why, And How](https://www.hansmichiels.com/2017/02/18/using-a-persistent-staging-area-what-why-and-how/)
  
-----

* [Data Architecture](https://www.techopedia.com/definition/6730/data-architecture) - Data architecture is a set of rules, policies, standards and models that govern and define the type of data collected and how it is used, stored, managed and integrated within an organization and its database systems. It provides a formal approach to creating and managing the flow of data and how it is processed across an organization’s IT systems and applications - techopedia


* [Data ethics](https://dataethics.eu/data-ethics-principles/) is about responsible and sustainable use of data. 

* [Data Exhaust](https://whatis.techtarget.com/definition/data-exhaust) - Data exhaust is the data generated as a byproduct of people’s online actions and choices - techtarget

* A [data estate](https://www.forbes.com/sites/forbestechcouncil/2019/04/05/why-the-modern-day-corporation-should-consider-a-data-estate/) is simply the infrastructure to help companies systematically manage all of their corporate data. A data estate can be developed on-premises, in the cloud or a combination of both (hybrid).

* [Data blending](https://www.datawatch.com/what-is-data-blending/) - Data blending is the process of combining data from multiple sources into a functioning dataset. This process is gaining attention among analysts and analytic companies due to the fact that it is a quick and straightforward method used to extract value from multiple data sources.

* [Data Owner](https://www.dataminingapps.com/2018/05/what-is-the-difference-between-a-data-owner-and-a-data-steward/) - Every data field in every database in the organization should be owned by a data owner, who is in the authority to ultimately decide on the access to, and usage of, the data.

* [Data steward](https://www.dataminingapps.com/2018/05/what-is-the-difference-between-a-data-owner-and-a-data-steward/) - Data stewards are the DQ experts in charge of ensuring the quality of both the actual business data and the corresponding metadata.  They assess DQ by performing extensive and regular data quality checks.  

* [Data Swamp](https://intersog.com/blog/what-is-the-difference-between-data-lakes-data-marts-data-swamps-and-data-cubes/) is the term that describes the failure to document the stored data accurately, resulting in the inability to analyze and exploit the data efficiently; the original data may remain, but the data swamp cannot retrieve it without the metadata that gives it context.

* [Data validation](https://www.mytutor.co.uk/answers/3636/GCSE/Computing/What-is-the-difference-between-data-verification-and-data-validation/) has nothing to do with what the user wants to input. Validation is about checking the input data to ensure it conforms with the data requirements of the system to avoid data errors. An example of this is a range check to avoid an input number that is greater/smaller than the specified range.

* [Data verification](https://www.mytutor.co.uk/answers/3636/GCSE/Computing/What-is-the-difference-between-data-verification-and-data-validation/) is a way of ensuring the user types in what he or she intends, in other words, to make sure the user does not make a mistake when inputting data. An example of this includes double entry of data (such as when creating a password or email) to prevent incorrect data input.

* Gartner defines [dark data](https://www.gartner.com/en/information-technology/glossary/dark-data) as the information assets organizations collect, process and store during regular business activities, but generally fail to use for other purposes (for example, analytics, business relationships and direct monetizing). 

* [Citizen Data Scientist](https://www.simplilearn.com/citizen-data-scientists-article) - A person who creates or generates models that leverage predictive or prescriptive analytics, but whose primary job function is outside of the field of statistics and analytics. simplilearn

* EIM   - Enterprise Information Management (Enterprise information management is an integrative discipline for structuring, describing and governing information assets across organizational and technological boundaries to improve efficiency, promote transparency and enable business insight) [Gartner IT Glossary](https://www.gartner.com/it-glossary/enterprise-information-management-eim)

* [Granularity](https://www.datasciencecentral.com/profiles/blogs/modelling-a-data-warehouse) refers to “the level of detail or summarisation of the units of data in the data warehouse”. The low level of granularity contains high level of detail and the high level of granularity contains low level of detail.

* [Information overload](https://en.wikipedia.org/wiki/Information_overload) (also known as infobesity, infoxication, information anxiety, and information explosion) is the difficulty in understanding an issue and effectively making decisions when one has too much information about that issue. In recent years, the term "information overload" has evolved into phrases such as "information glut", "data smog", and "data glut".

* [Raw Data](https://www.displayr.com/what-is-raw-data/) Raw data typically refers to tables of data where each row contains an observation and each column represents a variable that describes some property of each observation. Data in this format is sometimes referred to as tidy data, flat data, primary data, atomic data, and unit record data. Sometimes raw data refers to data that has not yet been processed.

* [Shadow It](https://www.gartner.com/en/information-technology/glossary/shadow) refers to IT devices, software and services outside the ownership or control of IT organizations.
